{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e481bbe0d6104666b11b4b5dff10a683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1600000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6974ec5b5bac43a3a61eca5a261cf99c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/498 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a1def7349348db87c6df021434b3b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c9b8c9950049ccb676f7527a1051a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/498 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed70094da30d49ce82376ba37e2d7069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520049ec96c8400fb3be6e57a2a13d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3fc42aa8b8414f9aef7ecebf483e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32659f38d19a4cd8b52d9f87a9d6e1c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc5472be608644e69383218a43ab3f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5\n",
      "------------------------------------------------------------\n",
      "Training Loss: 0.3916\n",
      "Training Accuracy: 82.24%\n",
      "Validation Loss: 0.3614\n",
      "Validation Accuracy: 84.14%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85     10000\n",
      "           1       0.87      0.81      0.84     10000\n",
      "\n",
      "    accuracy                           0.84     20000\n",
      "   macro avg       0.84      0.84      0.84     20000\n",
      "weighted avg       0.84      0.84      0.84     20000\n",
      "\n",
      "New best model saved with validation accuracy: 84.14%\n",
      "\n",
      "Epoch 2/5\n",
      "------------------------------------------------------------\n",
      "Training Loss: 0.2827\n",
      "Training Accuracy: 88.25%\n",
      "Validation Loss: 0.3598\n",
      "Validation Accuracy: 84.25%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85     10000\n",
      "           1       0.85      0.83      0.84     10000\n",
      "\n",
      "    accuracy                           0.84     20000\n",
      "   macro avg       0.84      0.84      0.84     20000\n",
      "weighted avg       0.84      0.84      0.84     20000\n",
      "\n",
      "New best model saved with validation accuracy: 84.25%\n",
      "\n",
      "Epoch 3/5\n",
      "------------------------------------------------------------\n",
      "Training Loss: 0.1781\n",
      "Training Accuracy: 93.06%\n",
      "Validation Loss: 0.4439\n",
      "Validation Accuracy: 84.08%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.85     10000\n",
      "           1       0.86      0.81      0.84     10000\n",
      "\n",
      "    accuracy                           0.84     20000\n",
      "   macro avg       0.84      0.84      0.84     20000\n",
      "weighted avg       0.84      0.84      0.84     20000\n",
      "\n",
      "\n",
      "Epoch 4/5\n",
      "------------------------------------------------------------\n",
      "Training Loss: 0.1000\n",
      "Training Accuracy: 96.36%\n",
      "Validation Loss: 0.5330\n",
      "Validation Accuracy: 83.79%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84     10000\n",
      "           1       0.85      0.82      0.84     10000\n",
      "\n",
      "    accuracy                           0.84     20000\n",
      "   macro avg       0.84      0.84      0.84     20000\n",
      "weighted avg       0.84      0.84      0.84     20000\n",
      "\n",
      "\n",
      "Epoch 5/5\n",
      "------------------------------------------------------------\n",
      "Training Loss: 0.0657\n",
      "Training Accuracy: 97.70%\n",
      "Validation Loss: 0.6593\n",
      "Validation Accuracy: 83.55%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.83     10000\n",
      "           1       0.82      0.85      0.84     10000\n",
      "\n",
      "    accuracy                           0.84     20000\n",
      "   macro avg       0.84      0.84      0.84     20000\n",
      "weighted avg       0.84      0.84      0.84     20000\n",
      "\n",
      "Early stopping triggered at epoch 5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.amp import autocast, GradScaler\n",
    "import numpy as np\n",
    "\n",
    "# Ensure you're running on GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def prepare_data(train_size=0.6, max_samples=None):\n",
    "    # Load dataset\n",
    "    dataset = load_dataset('sentiment140')\n",
    "\n",
    "    # Convert sentiment labels from [0, 4] to [0, 1]\n",
    "    # 0 = negative (0), 4 = positive (1)\n",
    "    dataset = dataset.map(lambda x: {'sentiment': 1 if x['sentiment'] == 4 else 0})\n",
    "\n",
    "    # Select balanced subset of data\n",
    "    train_data = dataset['train']\n",
    "    if max_samples:\n",
    "        pos_indices = [i for i, label in enumerate(train_data['sentiment']) if label == 1]\n",
    "        neg_indices = [i for i, label in enumerate(train_data['sentiment']) if label == 0]\n",
    "\n",
    "        # Randomly sample equal numbers of positive and negative examples\n",
    "        samples_per_class = min(len(pos_indices), len(neg_indices), max_samples // 2)\n",
    "        pos_indices = np.random.choice(pos_indices, samples_per_class, replace=False)\n",
    "        neg_indices = np.random.choice(neg_indices, samples_per_class, replace=False)\n",
    "\n",
    "        # Combine and shuffle indices\n",
    "        selected_indices = np.concatenate([pos_indices, neg_indices])\n",
    "        np.random.shuffle(selected_indices)\n",
    "        train_data = train_data.select(selected_indices)\n",
    "\n",
    "    # Split into train and validation\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "        train_data['text'],\n",
    "        train_data['sentiment'],\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=train_data['sentiment']  # Ensure balanced split\n",
    "    )\n",
    "\n",
    "    return train_texts, val_texts, train_labels, val_labels\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])  # Ensure text is string\n",
    "        label = int(self.labels[idx])  # Ensure label is integer\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, n_epochs, scaler, patience=3):\n",
    "    best_val_acc = 0\n",
    "    best_epoch = 0\n",
    "    no_improvement_epochs = 0\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [],\n",
    "        'val_loss': [], 'val_acc': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast('cuda'):\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                loss = criterion(outputs.logits, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                loss = criterion(outputs.logits, labels)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs.logits, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Calculate metrics\n",
    "        train_loss = total_train_loss / len(train_loader)\n",
    "        train_acc = (train_correct / train_total) * 100\n",
    "        val_loss = total_val_loss / len(val_loader)\n",
    "        val_acc = (val_correct / val_total) * 100\n",
    "\n",
    "        # Store metrics\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "        # Print metrics\n",
    "        print(f'\\nEpoch {epoch+1}/{n_epochs}')\n",
    "        print('-' * 60)\n",
    "        print(f'Training Loss: {train_loss:.4f}')\n",
    "        print(f'Training Accuracy: {train_acc:.2f}%')\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "        print(f'Validation Accuracy: {val_acc:.2f}%')\n",
    "        print('\\nClassification Report:')\n",
    "        print(classification_report(all_labels, all_predictions))\n",
    "\n",
    "        # Early stopping\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_epoch = epoch\n",
    "            no_improvement_epochs = 0\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_accuracy': best_val_acc,\n",
    "            }, 'best_model.pth')\n",
    "            print(f'New best model saved with validation accuracy: {val_acc:.2f}%')\n",
    "        else:\n",
    "            no_improvement_epochs += 1\n",
    "            if no_improvement_epochs >= patience:\n",
    "                print(f'Early stopping triggered at epoch {epoch+1}')\n",
    "                break\n",
    "\n",
    "    return history\n",
    "\n",
    "def main():\n",
    "    # Prepare data\n",
    "    train_texts, val_texts, train_labels, val_labels = prepare_data(train_size=0.6, max_samples=100000)\n",
    "\n",
    "    # Initialize tokenizer and model\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        'bert-base-uncased',\n",
    "        num_labels=2\n",
    "    ).to(device)\n",
    "\n",
    "    # Create datasets and dataloaders\n",
    "    train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)\n",
    "    val_dataset = SentimentDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        num_workers=2  # Reduced from 4 to avoid warnings\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=32,\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    # Initialize training components\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scaler = GradScaler('cuda')\n",
    "\n",
    "    # Train model\n",
    "    history = train_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        n_epochs=5,\n",
    "        scaler=scaler,\n",
    "        patience=3\n",
    "    )\n",
    "\n",
    "    return history\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "<ipython-input-4-88c740c8d906>:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('best_model.pth', map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: 'I love this! ğŸ˜Šâ¤ï¸' => Sentiment: Positive\n",
      "Sentence: 'This is terrible... ğŸ˜¡ğŸ‘' => Sentiment: Negative\n",
      "Sentence: 'I had a great day ğŸ˜ğŸ‰' => Sentiment: Positive\n",
      "Sentence: 'I can't stand this anymore ğŸ˜¤ğŸ˜' => Sentiment: Negative\n",
      "Sentence: 'Absolutely amazing! ğŸ‘ğŸ˜Š' => Sentiment: Positive\n",
      "Sentence: 'This is disappointing ğŸ˜¢' => Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Ensure you're using the right device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Reinitialize the model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=2\n",
    ").to(device)\n",
    "\n",
    "# Load the trained model weights\n",
    "checkpoint = torch.load('best_model.pth', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Define function to preprocess and make predictions\n",
    "def predict_sentiment(sentences, tokenizer, model):\n",
    "    inputs = tokenizer(\n",
    "        sentences,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=128,\n",
    "        return_tensors='pt'\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        _, predictions = torch.max(outputs.logits, 1)\n",
    "\n",
    "    # Convert predictions to human-readable labels\n",
    "    sentiment_labels = ['Negative' if label == 0 else 'Positive' for label in predictions]\n",
    "    return sentiment_labels\n",
    "\n",
    "# Example custom sentences with emojis\n",
    "custom_sentences = [\n",
    "    \"I love this! ğŸ˜Šâ¤ï¸\",\n",
    "    \"This is terrible... ğŸ˜¡ğŸ‘\",\n",
    "    \"I had a great day ğŸ˜ğŸ‰\",\n",
    "    \"I can't stand this anymore ğŸ˜¤ğŸ˜\",\n",
    "    \"Absolutely amazing! ğŸ‘ğŸ˜Š\",\n",
    "    \"This is disappointing ğŸ˜¢\"\n",
    "]\n",
    "\n",
    "# Predict sentiment for custom sentences\n",
    "predictions = predict_sentiment(custom_sentences, tokenizer, model)\n",
    "for sentence, prediction in zip(custom_sentences, predictions):\n",
    "    print(f\"Sentence: '{sentence}' => Sentiment: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "<ipython-input-12-0475404f030d>:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('best_model.pth', map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on custom sentences: 100.00%\n",
      "Sentence: 'I love this! ğŸ˜Šâ¤ï¸' => Predicted: Positive, True: Positive\n",
      "Sentence: 'This is terrible... ğŸ˜¡ğŸ‘' => Predicted: Negative, True: Negative\n",
      "Sentence: 'I had a great day ğŸ˜ğŸ‰' => Predicted: Positive, True: Positive\n",
      "Sentence: 'I can't stand this anymore ğŸ˜¤ğŸ˜' => Predicted: Negative, True: Negative\n",
      "Sentence: 'Absolutely amazing! ğŸ‘ğŸ˜Š' => Predicted: Positive, True: Positive\n",
      "Sentence: 'This is disappointing ğŸ˜¢' => Predicted: Negative, True: Negative\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Ensure you're using the right device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Reinitialize the model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=2\n",
    ").to(device)\n",
    "\n",
    "# Load the trained model weights\n",
    "checkpoint = torch.load('best_model.pth', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Function to predict sentiment labels\n",
    "def predict_sentiment(sentences, tokenizer, model):\n",
    "    inputs = tokenizer(\n",
    "        sentences,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=128,\n",
    "        return_tensors='pt'\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        _, predictions = torch.max(outputs.logits, 1)\n",
    "\n",
    "    return predictions.cpu().numpy()\n",
    "\n",
    "# Example custom sentences and their true labels (0 = Negative, 1 = Positive)\n",
    "custom_sentences = [\n",
    "    \"I love this! ğŸ˜Šâ¤ï¸\",\n",
    "    \"This is terrible... ğŸ˜¡ğŸ‘\",\n",
    "    \"I had a great day ğŸ˜ğŸ‰\",\n",
    "    \"I can't stand this anymore ğŸ˜¤ğŸ˜\",\n",
    "    \"Absolutely amazing! ğŸ‘ğŸ˜Š\",\n",
    "    \"This is disappointing ğŸ˜¢\"\n",
    "]\n",
    "\n",
    "# True labels for evaluation (e.g., [1, 0, 1, 0, 1, 0])\n",
    "true_labels = [1, 0, 1, 0, 1, 0]\n",
    "\n",
    "# Predict sentiment for custom sentences\n",
    "predictions = predict_sentiment(custom_sentences, tokenizer, model)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(f\"Accuracy on custom sentences: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Optionally, print predictions\n",
    "for sentence, prediction, true_label in zip(custom_sentences, predictions, true_labels):\n",
    "    sentiment = \"Positive\" if prediction == 1 else \"Negative\"\n",
    "    print(f\"Sentence: '{sentence}' => Predicted: {sentiment}, True: {'Positive' if true_label == 1 else 'Negative'}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
